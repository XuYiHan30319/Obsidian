# 机器学习概述
![[Pasted image 20230329104133.png]]
统计学习:是机器学习和数据挖掘这两门技术的基础,更偏重于理论上的完善,统计学习主要通过机器学习为数据挖掘提供算法支撑
机器学习:是统计学习对实践技术的延伸,更偏重解决小数据量的问题
数据挖掘:更偏重大数据的实际问题,更注重实际问题的解决,包括真实数据的清洗,建模,预测等操作,机器学习和数据库是数据挖掘的最大支撑技术.
## 机器学习的定义
机器学习:研究如何使机器模拟或实现人类的学习行为,以获取知识和技能,并不断改善系统自身性能的学科,根本任务是数据的智能分析和建模,并从数据中挖掘出有价值的信息
### 机器学习的分类
机器学习可以分为传统机器学习方法和给予卷积神经网络的深度学习方法
机器学习的研究主要分为两类
- 基于统计学的传统机器学习,主要研究学习机制,注重探索模拟人的学习机制
- 基于大数据和人工神经网络的深度学习,主要研究如何充分利用大数据时代下的海量数据,获得有价值的信息
### 机器学习的流派
- 联结主义
- 符号主义
- 行为主义
## 机器学习基本术语
- 数据集:数据的集合
- 样本:也叫做实例,指研究对象的个体,比如研究学生群体,学生就是样本
- 标签:样本中指定的数值或者类别,比如学生打个标签男/女
- 特征:样本的一个可观测的属性和特征,比如特征颜色的特征值是黑色
- 特征向量:样本的n个属性组成的n维向量
- 手工特征:研究者设计的特征
- 特征空间:指特征向量所在的p维空间,每一个样本都是空间中的一个点,也叫样本空间,比如升高体重两个坐标轴,每个学生都能在这个特征空间中找到自己的位置坐标
- 训练集:训练中提供的训练数据,每个训练数据叫一个训练样本.
	- 每个训练样本都有一个已知标签,由所有训练样本及其标签组成的集合叫做训练集,即训练集包含一个样本集和对应的标签集,用于学习得到拟合样本的模型
	- 比如完成图像分类后,所用到的训练集就是一个由特定图形组成的样本集合和一组由语义概念组成的标签集合
- 验证集:实际训练的时候,容易出现在训练集上的效果很好,但是对于训练集之外的数据结果不好,因此我们单独留出一本分样本用于验证和调整超参数
	- 超参数:就是模型中人为设定的无法通过训练得到的参数,调参侠调的就是这个
- 测试集:用来测试
- 泛化能力:训练得到的模型处理未知样本的能力
- 模型参数:给定训练集,我们希望能拟合一个函数f(x,θ)完成输入的特征到标签的映射,这个函数就是输出值,θ是模型中学习的参数,即模型参数,就是程序要训练的值
- 学习算法:希望给每个样本预测的标签与其真实标签值相同,需要有一组好的模型参数.为了获得这样的参数,我们就需要有一套学习算法来优函数f,这个优化过程就叫学习/训练,拟合函数f就叫模型
- 假设空间:假设空间就是将特征空间映射到标签集的函数f的集合.学习的目的就是再到一个最优的模型
## 机器学习的三个不同视角
1. 学习任务 分类,回归,聚类,排名,降维
2. 学习范式 有无数据,环境互动
3. 学习模型 表示可以完成一个学习任务的方法(SVM,KNN)
## 机器学习的任务
1. 分类 输入划分为两个或多个类别,输出值是离散的
	1. 应用 垃圾邮件过滤,人脸识别,手写体,反欺诈
	2. 算法:SVM,KNN,朴素贝叶斯,决策树,逻辑回归
2. 回归:确定某些变量之间定量关系的一种统计分析方法,即建立数学模型并估计未知参数,给定一个输入特征值x,便能给出一个对应的连续数据(非离散),比如根据地段等信息预测房价
	1. 应用:预测股票,二手车价格,升高梯子,医学诊断
	2. 算法:多远线性回归,贝叶斯线性回归,多项式回归
3. 聚类:将具体的或者抽象的对象的集合分为多个由相似对象组成的多个不知名的组或者簇
	1. 应用:找出潜在目标用户和市场
	2. 算法:k-means,层次聚类
4. 排名:基于某个准则排序
	1. 比如网页排名算法
## 学习范式
监督学习:采用一组有标注的数据样本对模型进行训练,再用训练好的模型对位置样本做出预测.训练数据由两部分组成,即描述事件的特征向量和真实标签,可以完成分类回归和排名
无监督学习:自己学,只有描述事件的特征向量,没有标签,主要完成聚类和降维,典型的无监督学习有K-means聚类,主成分分析法PCA
弱监督学习:介于监督学习和无监督学习之间,利用带有弱标签的训练数据集进行监督学习,同时利用大量无标签数据进行无监督学习,根据训练使用的数据集质量,分为不完全(又分为主动学习,半监督学习,迁移学习,强化学习),不确切和不准确监督学习
## 学习模型
![[Pasted image 20230425172543.png]]

# 监督学习
有监督学习的训练数据:每个训练数据具有一个已知标注作为输入数据
标注是输入数据和预期输出组成的对.
整理好测试集和训练集,保证两个数据集不相交
## 评价监督学习的性能
若所学习得到的模型能很好地拟合训练集,这种拟合能力称为学习能力或者训练能力或者逼近能力
训练模型对测试集也能输出正确的结果,这种能力叫做预测能力或者泛化能力或者推广能力.如果不嫩很好的逼近,叫做欠拟合,很好拟合叫做良拟合.当超过某个极限,会导致过拟合,一般发生在模型过于复杂或者训练数据不足的情况下
## 监督学习的主要任务
1. 分类,输出空间Y是一组离散的类别,用于分类的算法叫做分类器,分类模型
2. 回归:输出空间Y是一组连续的实数值,比如房价预测,二手车价格
3. 排名:输出一组相对的顺序
![[Pasted image 20230425173532.png]]
![[Pasted image 20230425173543.png]]
![[Pasted image 20230425173823.png]]
## 回归
回归就是预测每个相的实数值
![[Pasted image 20230425174045.png]]
## 逻辑回归
<font color="#ff0000">用于分类!</font>是通过历史数据对未来结果发生的概率进行预测,比如把用户年龄,性别设为自变量,采购概率作为因变量.
回归的自变量可以是1个也可以是多个,因变量可以是二分类,也可以是多分类.通常使用二分类
用sigmoid函数,也就是二分类,如果阈值调制0.5,那么大于0.5一类,小于0.5一类.使用softmax就是多分类
![[Pasted image 20230425174532.png]]
![[Pasted image 20230425174554.png]]

线性回归被广泛的用于预报和预测

## KNN k-nearest Neighbor
KNN算法是典型的监督学习算法,可以用于分类,也可用于回归
分类:给定待测样本A,在特征空间找出与样本A最相似的k个样本,然后统计k个样本所属的类别,找出样本数最多的类别,则样本a就属于这个类别
回归:找出一个样本A在特征空间k个最相似的样本,将这K个样本属性的平均値付给A![[Pasted image 20230425182243.png]]就相当于画一个一定范围的圈圈,看看圈圈里面那个最多
## 支持向量机(分类)
![[Pasted image 20230425182335.png]]
我们要找出所有分类器中效果最好的那个
如何评价效果呢?我们采取间隔的方式,如果一条斜线的斜率能使得两端切线的斜率达到最大,那就是最好的
![[Pasted image 20230425182503.png]]
间隔:再碰到数据点之前边界的宽度,直观上间隔越大越好.
由数学,我们可以得到![[Pasted image 20230425182647.png]]
# 无监督学习
接受未标注数据,并对所有未知点做出预测,其目标是发现数据中共性的东西或者减少正在考虑的随机变量的数量.无监督学习没有<font color="#ff0000">训练过程</font>,给定一些对象数据,让机器学习算法直接对这些数据分析得到数据的某些知识
## 聚类
聚类是将样本进行分组的任务,使得同一组中的样本呢彼此之间比其他样本更加相似,即,聚类是将相似的输入样本分在同一类别
## 降维
通过某种数学变换,将原时高维数据属性空间转变为一个低纬度子空间,因为在高位空间中,样本特征可能有冗余信息和噪声,造成空间浪费,计算量太大,无法获取本质特征等问题
降维主要用于三方面
1. 数据压缩,压缩后的图像视频等不仅减少了占用的存储空间,还加速了算法运行
2. 数据可视化:通过降维可以得到更加直观的数据视图,例如将四维升职更高维度的数据降到2,3维度
3. 特征工程:高维数据中的次要信息会对识别造成误差,降低模型的准确度,增加模型复杂度,出现过拟合

在特征工程中,我们常常采用特征选择和特征提取的方式
1. 特征选择:选择n个最有效的
2. 特征提取:将机器学习无法识别的原始数据转化为算法可以识别的数值特征.降维的特征提取是指通过数学变换,将高纬度投影到低纬度中

## K-means算法
1. 随机选择k个点作为初识中心
2. 计算每个对象和k的距离,并将他划分到最近的簇
3. 重新计算每个簇的中心
4. 重新执行2,3知道中心不再变化

损失函数为每个点到自己促中心的距离平方和,达到类中节点足够近,类的点足够远

# 弱监督学习
数据集中有少部分的标注,大部分没有标注,即使有标注,可能也质量不高,有噪声.
弱监督学习就是根据已知的数据和弱标签训练一个人工智能.与监督学习相比,弱监督学习的数据标签不完整,相比无监督学习,又有一部分标签
## 不确切监督学习
样本只有粗粒度的标签.比如图中有两只猫,现在只标注了整张图的类别为猫,而没有标注猫的边界,只有图像级别的标准,没有对象级的标注
通常采用多实例学习技术改善和解决.
一个包就是多个实例,但包中的实例都没有标签.一旦包中至少有一个正实例,叫正包,如果全是负的,叫负包
## 不准确监督学习
就是有时候样本的训练标签不总是正确的,我们称之为标签有噪声.一个典型的想法就是识别出潜在的错误标签,然后更正
## 不完全监督学习
当训练集只有一个很小的子集有标签,所进行的叫不完全监督学习.
### 主动学习
可以把最有价值的模型向人类专家查询,为其打上标签
算法主动从样本池选择下一个需要标记的可用样本子集.然后向人询问标记.可以通过更少的训练标签获得更高的精度.主动学习选择最重要,信息量最大的样本.
主动学习步骤如下:1.主动选择样本 2.人工标注 3.模型训练 4.模型预测 5.模型更新
### 半监督学习
通过学习已有数据标签,逐步扩展,无需人的参与
![[Pasted image 20230430091500.png]]
### 迁移学习
通过相似的模型迁移到自己,主要寻找元领域和目标领域的相似.
又分为:样本迁移: 寻找任务AB中相似的标注数据,直接拿来训练B的模型,需要加强该样本的权值
模型迁移:把模型的一部分或者全部参数都拿来应用
特征迁移:通过特征变换把原来的领域的特征拿来
### 强化学习
不断试错,使得下一步行动能获得更多的奖励,并且让奖励最大化





