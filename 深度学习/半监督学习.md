图像分割就是讲图像换分为许多不重叠的区域,并将标签分给每个区域.深度学习的方法在cv领域大放异彩,但是由于需要对每个像素都进行标注,导致监督学习非常消耗人力.因此,许多研究人员更加倾向半监督学习.这些半监督学习方法从有标签的数据中学习,并且从无标签的数据中提取知识,减少需要的标签数据,同时也获得了比无监督学习更好的效果
半监督学习
1. 主动学习:将未标记的数据给人类专家查看,得到新的标注数据后继续迭代
2. 归纳学习:从大量的样本中学习得到数据的潜在规律(基于开放世界?),可以预测样本集之外的数据
3. 直推学习:直接在样本集上训练,想要在样本集上达到最好的效果,只能处理当前的样本集

## 自我训练/伪标签技术
在已知的标签上训练,然后预测未知的标签,取置信度最高的样本进行标签定义,然后把他放入已知的样本集中继续训练,比如分类问题,假设我得到的图片的置信度是0.99,那么我把这张图纳入自己的有标记的训练样本集合中继续训练,对于初识模型精度要求比较高
这其实是一种数据增广的方式,但是只有在初始和后续的类别中的标记绝大多数才是正确的才有可能提升模型效果

## 问题
1. 无标签样本如何有效利用:如果无标签数据的质量差甚至是分布完全不一致的数据,那么反而容易降低模型的泛化能力
2. 半监督学习算法的计算复杂度,性能提升以及可扩展性差
3. 对于特征非常敏感,需要数据集效果好
4. 对于图像这种非结构化效果比较好,可以进行增广



## 对比学习
发现数据中潜在的结构，对比式学习不需要关注实例上繁琐的细节，只需要在抽象语义级别的特征空间上学会对数据的区分即可，因此模型以及其优化变得更加简单，且泛化能力更强。![[Pasted image 20230917105655.png]]
对比学习的目标是学习一个编码器,一般是cnn,使得同类数据进行相似的编码,不同类数据不同编码,得到一组特征向量.然后对于一个锚样本,需要与正样本距离近而和负样本距离远,一般使用infoNCE来充当损失函数
像素级别的语义分割->即模型最终输出一个和原图同等大小，通道数为语义类别数量的特征图（Y）

对于图片中的某个固定锚点,其位置是由与其他点的相对位置决定的而不是绝对位置.可以这么认为，通过对比学习，忽略了细节，找到并确定所以关键点相对位置。
![[Pasted image 20230917120318.png]]
比如这个,就是把不同的像素映射到一个像素空间,然后拉进相同类别的距离而推远其他的,这样就可以的到一个效果更好的特征空间.

## 深度度量学习
>深度度量学习是一种机器学习方法，它的目标是通过学习将输入数据映射到一个具有良好度量性质的低维空间。在这个低维空间中，数据点之间的距离应该反映它们的相似性或差异性。深度度量学习通常通过神经网络模型来实现。
 与传统的监督学习不同，深度度量学习不需要标注的类别信息作为训练目标。相反，它利用数据实例之间的相似度或距离作为监督信号来训练模型。通过优化损失函数，模型可以学习到一个能够在低维嵌入空间中保持相似实例靠近、不相似实例远离的映射。
 深度度量学习在很多计算机视觉任务中都有广泛应用，例如人脸识别、图像检索、目标跟踪等。它可以帮助计算机更准确地理解和比较图像、文本、声音等多种形式的数据。通过学习适当的度量，深度度量学习可以为许多实际应用提供更好的性能和效果。

## 端到端的特征学习
端到端的特征学习是指使用端到端的深度学习模型从原始输入数据中直接学习出具有判别能力的特征表示。传统的机器学习方法通常需要手工设计特征，将数据转换为适合模型处理的形式。而端到端的特征学习则试图通过深度神经网络自动地学习出数据的高层次抽象特征，无需人为干预。
