## RNN的意义
RNN只能处理单个的一个个输入,前后完全没有关系,但是有些任务为了更好的处理序列信息(就是前后输入是有关系的),为了更好的处理序列信息,rnn就诞生了
![[Pasted image 20230901094729.png]]
RNN的结构如上所示,也就是说输入序列进过权重矩阵U之后输入S,然后S的结果经过权重矩阵w后和x结合再输入s中循环得到结果,再经过权重矩阵后输出.按照时间维度展开后变成这样
![[Pasted image 20230901095444.png]]
在t时刻接收到$x_t$后输出$s_t$然后和下一层的$x_{t+1}$结合得到新的值,就这样就可以循环计算得到新的值了
![[Pasted image 20230901095657.png]]
## LSTM
长短期记忆网络是一种特殊的RNN,为了解决长序列训练过程中的梯度问题![[Pasted image 20230901100123.png]]
相比传统RNN只有一个传递状态,LSTM有两个状态.其中$c^t$的变化速度很慢,通常是上一个状态加上某个数值,而$h^t$则变化的较快.
![[Pasted image 20230901100534.png]]![[Pasted image 20230901100631.png]]
LSTM内部的细节如图,首先使用LSTM对当前输入xt和上一个状态的ht-1拼接得到4个训练状态,其中下面三个是使用softmax映射到01,z是使用tanh映射到-1~1
## 下面是具体的计算过程
![[Pasted image 20230901100855.png]]
LSTM的过程有三个阶段
1. 忘记阶段.对上一个节点的输入$c_{t-1}$选择性忘记,使用zf忘记门表示,
2. 选择记忆. 对输入xt选择性记忆,那些重要记下来,不重要就扔掉,使用z表示当前输入的计算,而zi表示选择门,记录哪些更重要.
3. zo控制输出,